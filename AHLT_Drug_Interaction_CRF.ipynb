{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from IPython.display import display # For displaying DataFrames correctly in Jupyter\n",
    "from sklearn import svm\n",
    "import scipy.stats # for RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, train_test_split # Parameter selection\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# Other libraries\n",
    "import time # Execution time of some blocks\n",
    "import statistics\n",
    "\n",
    "# Import our own defined functions\n",
    "from xlm_parsers_functions import *\n",
    "from drug_interaction_functions import *\n",
    "from drug_functions import *\n",
    "from NER_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/Train/DrugBank/'\n",
    "\n",
    "def readXMLData(data_dir):\n",
    "\n",
    "    # Use xlm_element.tag to get the name of the xlm element\n",
    "    # Use xlm_element.attrib to get all the attributes of the xlm element as a string\n",
    "\n",
    "    # Parse the DrugBank Files\n",
    "    drugs_dataset = []\n",
    "    #parent_directory = '../LaboCase/small_train_DrugBank/'\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            # Parse the file\n",
    "            tree = ET.parse(data_dir + filename)\n",
    "            # Create a list of lists with the interactions of the file\n",
    "            drugs_dataset = drugs_dataset + listDDIFromXML(tree.getroot())\n",
    "\n",
    "    return(drugs_dataset)\n",
    "\n",
    "# Create a list of lists with the interactions of the file\n",
    "XMLdata = readXMLData(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with(open('data/DrugBank_names_DB.txt', 'r')) as f:\n",
    "    drugbank_db = f.read().splitlines()\n",
    "    \n",
    "def sent2features(tupl, i, database):\n",
    "    \n",
    "    if len(tupl) != 5:\n",
    "        raise ValueError('The introduced tuple does not have the correct length')\n",
    "    sent = tupl[0]\n",
    "    ent1 = tupl[1]\n",
    "    ent2 = tupl[2]\n",
    "    ent_list = tupl[3]\n",
    "    \n",
    "    features = {\n",
    "        \n",
    "    'ent1': ent1,\n",
    "    'ent2': ent2,\n",
    "    # Orthographic features\n",
    "        \n",
    "    # Entity 1\n",
    "    'ent1_all_uppercase_letters' : allCaps(ent1), \n",
    "    'ent1_initial_capital_letter': initCap(ent1), \n",
    "    'ent1_contains_capital_letter' : hasCap(ent1),\n",
    "    'ent1_single_capital_letter' : singleCap(ent1),\n",
    "    'ent1_punctuation' : punctuation(ent1),\n",
    "    'ent1_initial_digit' : initDigit(ent1),\n",
    "    'ent1_single_digit' : singleDigit(ent1),\n",
    "    'ent1_letter_and_num' : alphaNum(ent1),\n",
    "    'ent1_many_numbers' : manyNum(ent1),\n",
    "    'ent1_contains_real_numbers' : realNum(ent1),\n",
    "    'ent1_intermediate_dash' : inDash(ent1),\n",
    "    'ent1_has_digit' : hasDigit(ent1),\n",
    "    'ent1_is_Dash' : isDash(ent1),\n",
    "    'ent1_is_roman_letter' : roman(ent1),\n",
    "    'ent1_is_end_punctuation' : endPunctuation(ent1),\n",
    "    'ent1_caps_mix' : capsMix(ent1),\n",
    "\n",
    "    # Entity 2\n",
    "    'ent2_all_uppercase_letters' : allCaps(ent2), \n",
    "    'ent2_initial_capital_letter': initCap(ent2), \n",
    "    'ent2_contains_capital_letter' : hasCap(ent2),\n",
    "    'ent2_single_capital_letter' : singleCap(ent2),\n",
    "    'ent2_punctuation' : punctuation(ent2),\n",
    "    'ent2_initial_digit' : initDigit(ent2),\n",
    "    'ent2_single_digit' : singleDigit(ent2),\n",
    "    'ent2_letter_and_num' : alphaNum(ent2),\n",
    "    'ent2_many_numbers' : manyNum(ent2),\n",
    "    'ent2_contains_real_numbers' : realNum(ent2),\n",
    "    'ent2_intermediate_dash' : inDash(ent2),\n",
    "    'ent2_has_digit' : hasDigit(ent2),\n",
    "    'ent2_is_Dash' : isDash(ent2),\n",
    "    'ent2_is_roman_letter' : roman(ent2),\n",
    "    'ent2_is_end_punctuation' : endPunctuation(ent2),\n",
    "    'ent2_caps_mix' : capsMix(ent2),\n",
    "        \n",
    "    # Morphological information: prefixes/suffixes of lengths from 2 to 5 and word shapes of tokens. \n",
    "    # Entity 1\n",
    "    'ent1_word[-5:]': ent1[-5:],\n",
    "    'ent1_word[-4:]': ent1[-4:],\n",
    "    'ent1_word[-3:]': ent1[-3:],\n",
    "    'ent1_word[-2:]': ent1[-2:],\n",
    "\n",
    "    # Entity 2\n",
    "    'ent2_word[-5:]': ent2[-5:],\n",
    "    'ent2_word[-4:]': ent2[-4:],\n",
    "    'ent2_word[-3:]': ent2[-3:],\n",
    "    'ent2_word[-2:]': ent2[-2:],\n",
    "    \n",
    "    # Domain knowledge\n",
    "    # Entity 1\n",
    "    'ent1_contains_drug_sufix': containsSufix(ent1),\n",
    "    'ent1_contains_drug_prefix': containsPrefix(ent1),\n",
    "\n",
    "    # Entity 2\n",
    "    'ent2_contains_drug_sufix': containsSufix(ent2),\n",
    "    'ent2_contains_drug_prefix': containsPrefix(ent2),\n",
    "        \n",
    "    # Is in DrugBank dataset\n",
    "    'ent1_isInDB':isTokenInDB(ent1,database),\n",
    "    'ent2_isInDB':isTokenInDB(ent2,database)\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def text2features(text,database):\n",
    "    for i in range(len(text)):\n",
    "        return(sent2features(text, i, drugbank_db))\n",
    "\n",
    "def text2labels(text):\n",
    "    return text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.25 s, sys: 110 ms, total: 7.36 s\n",
      "Wall time: 7.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = [[text2features(s, drugbank_db)] for s in XMLdata]\n",
    "y = [[text2labels(s)] for s in XMLdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences:  16643\n",
      "Number of testing sentences:  5201\n"
     ]
    }
   ],
   "source": [
    "seed = 16273\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle = True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, shuffle = True)\n",
    "print('Number of training sentences: ', len(X_train))\n",
    "print('Number of testing sentences: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.57 s, sys: 53.5 ms, total: 3.63 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('none')\n",
    "labels\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3019108280254777"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i][0] is None:\n",
    "        print(i)\n",
    "        y_pred[i][0] = 'none'\n",
    "    \n",
    "    if y_test[i][0] is None:\n",
    "        print(i)\n",
    "        y_test[i][0] = 'none'\n",
    "        \n",
    "sklearn.metrics.recall_score(y_true = y_test, \n",
    "                             y_pred = y_pred, \n",
    "                             labels=labels, \n",
    "                             pos_label=1, \n",
    "                             average='weighted',\n",
    "                             sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def transformStrCategoriesIntoInts(vector):\n",
    "    res = []\n",
    "    for el in vector:\n",
    "        if el == 'none' or el == 'None':\n",
    "            res.append(0)\n",
    "        elif el == 'mechanism':\n",
    "            res.append(1)\n",
    "        elif el == 'effect':\n",
    "            res.append(2)\n",
    "        elif el == 'int':\n",
    "            res.append(3)\n",
    "        elif el == 'advise':\n",
    "            res.append(4)\n",
    "        else:\n",
    "            print(el)\n",
    "            print(type(el))\n",
    "            print(vector.index(el))\n",
    "    return(res)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
