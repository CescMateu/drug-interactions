{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Name Entity Classifier\n",
    "## AHLT - MIRI 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bio_tagger import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/Train'\\ntrain_dirs_whereto_parse = [train_dir+'/DrugBank',train_dir+'/MedLine']\\ntest_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/Test'\\ntest_dirs_whereto_parse = [test_dir+'/DrugBankOutput',test_dir+'/MedLineOutput']\\n\\ntrain_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/'\\ntrain_dirs_whereto_parse = [train_dir+'/Small Train']\\n\\ntest_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/'\\ntest_dirs_whereto_parse = [test_dir+'/Small Test']\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cesc\n",
    "'''\n",
    "train_dir = '../LaboCase/Train/'\n",
    "dirs_whereto_parse = [train_dir+'/test_DrugBank']\n",
    "'''\n",
    "\n",
    "train_dir = '../LaboCase/'\n",
    "train_dirs_whereto_parse = [train_dir+'/small_train_DrugBank']\n",
    "\n",
    "test_dir = '../LaboCase/'\n",
    "test_dirs_whereto_parse = [test_dir+'/small_test_DrugBank']\n",
    "\n",
    "# Miki\n",
    "'''\n",
    "train_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/Train'\n",
    "train_dirs_whereto_parse = [train_dir+'/DrugBank',train_dir+'/MedLine']\n",
    "test_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/Test'\n",
    "test_dirs_whereto_parse = [test_dir+'/DrugBankOutput',test_dir+'/MedLineOutput']\n",
    "\n",
    "train_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/'\n",
    "train_dirs_whereto_parse = [train_dir+'/Small Train']\n",
    "\n",
    "test_dir = '/Users/miqueltubaupires/Documents/Master/3r QUATRIMESTRE/AHLT/Lab/ddi/'\n",
    "test_dirs_whereto_parse = [test_dir+'/Small Test']\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading train data\n",
    "Accessing to all the files of the directory and storing id's and text's in two arrays.\n",
    "We have also added the tokens 'START' and 'STOP' at the beginning and end of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities=[]\n",
    "texts=[]\n",
    "train_texts_entities = []\n",
    "\n",
    "for directory in train_dirs_whereto_parse:\n",
    "    name_files=listdir(directory)   # querying all the files that are in that directory\n",
    "    # Parse all these xml files\n",
    "    roots = [etree.parse(directory+'/'+a).getroot() for a in name_files if a.endswith('.xml')]\n",
    "    for root in roots:\n",
    "        for sentence in root.findall('sentence'):\n",
    "            for entity in sentence.findall('entity'):\n",
    "                entities = entities+[entity.get('text')]\n",
    "            train_texts_entities = train_texts_entities + [('START ' + sentence.get('text') + ' STOP',entities)]\n",
    "            entities =[]\n",
    "\n",
    "# train_texts_entities is a list of tuples. Each one is comprised of the sentence and the drugs in there\n",
    "# print(texts_entities[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Laboratory Tests Response to Plenaxis should be monitored by measuring serum total testosterone concentrations just prior to administration on Day 29 and every 8 weeks thereafter.\\n', ['testosterone', 'Plenaxis'])\n"
     ]
    }
   ],
   "source": [
    "test_texts = []\n",
    "test_entities = []\n",
    "for directory in test_dirs_whereto_parse:\n",
    "    name_files = listdir(directory)\n",
    "    # Si no poso el sorted, em llegeix els files amb un ordre aleatori.\n",
    "    # Amb el sorted m'asseguro que els corresponents files text.txt i entities.txt estan en la mateixa posicio\n",
    "    text_file_names = sorted([directory+'/'+a for a in name_files if a.endswith('text.txt')])\n",
    "    entities_file_names = sorted([directory+'/'+a for a in name_files if a.endswith('entities.txt')])\n",
    "    for file in text_file_names:\n",
    "        file = open(file,'r')\n",
    "        test_texts = test_texts + [file.read()]\n",
    "    for file in entities_file_names:\n",
    "        read_entities = []\n",
    "        with open(file,'r') as f:\n",
    "            for line in f:\n",
    "                read_entities = read_entities+[' '.join(line.split()[0:-1])] # separo en words, el.limino la ultima i torno a unir\n",
    "        test_entities.append(read_entities)\n",
    "        \n",
    "# test_texts_entities is a list of tuples. Each one is comprised of the sentence and the drugs in there\n",
    "test_texts_entities=list(zip(test_texts,test_entities))\n",
    "print(test_texts_entities[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIO TAGGER\n",
    "\n",
    "Let's try to tag each sentence with the BIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "tags = []\n",
    "for text,drugs in train_texts_entities:\n",
    "    tuples = bio_tagger(text,drugs)\n",
    "    tokens = tokens + [word[0] for word in tuples]\n",
    "    tags = tags + [word[1] for word in tuples]\n",
    "\n",
    "train_set = {'token':tokens,'output':tags}\n",
    "train_df = pd.DataFrame(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>START</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>Formal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "      <td>studies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  output        token\n",
       "0      O        START\n",
       "1      O       Formal\n",
       "2      O         drug\n",
       "3      O  interaction\n",
       "4      O      studies"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the features for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_capitalized</th>\n",
       "      <th>is_total_capitalized</th>\n",
       "      <th>output</th>\n",
       "      <th>prefix_feature</th>\n",
       "      <th>suffix_feature</th>\n",
       "      <th>token</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>START</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Formal</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>drug</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>interaction</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>studies</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_capitalized  is_total_capitalized output  prefix_feature  \\\n",
       "0               1                     1      O               0   \n",
       "1               1                     0      O               0   \n",
       "2               0                     0      O               0   \n",
       "3               0                     0      O               0   \n",
       "4               0                     0      O               0   \n",
       "\n",
       "   suffix_feature        token  token_length  \n",
       "0               0        START             5  \n",
       "1               1       Formal             6  \n",
       "2               0         drug             4  \n",
       "3               0  interaction            11  \n",
       "4               0      studies             7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_vector(tokenized_sentence):\n",
    "    feature_vector = {}\n",
    "    # Feature 1: Length of the token\n",
    "    feature_vector['token_length'] = [len(token) for token in tokenized_sentence]\n",
    "\n",
    "    # Feature 2: Is the the first letter of the word capitalized?\n",
    "    is_capitalized = [1 if row[0].isupper() else 0 for row in tokenized_sentence]\n",
    "    feature_vector['is_capitalized'] = is_capitalized\n",
    "\n",
    "    # Feature 3: Is the token completely capitalized?\n",
    "    is_total_capitalized = [1 if row.isupper() else 0 for row in tokenized_sentence]\n",
    "    feature_vector['is_total_capitalized'] = is_total_capitalized\n",
    "    \n",
    "    # Feature 4 & 5: Prefixes and Suffixes\n",
    "\n",
    "    prefix_feature = []\n",
    "    suffix_feature = []\n",
    "\n",
    "    prefixes = r'^meth|^eth|^prop|^but|^pent|^hex|^hept|^oct|^non|^dec'\n",
    "    suffixes = r'ane$|ene$|yne$|ol$|al$|amine$|cid$|ium$|ether$|ate$|one$'\n",
    "\n",
    "    for token in tokenized_sentence:\n",
    "\n",
    "            if re.search(prefixes,token):\n",
    "                prefix_feature=prefix_feature+[1]\n",
    "            else:\n",
    "                prefix_feature = prefix_feature+[0]\n",
    "\n",
    "            if re.search(suffixes,token):\n",
    "                suffix_feature=suffix_feature+[1]\n",
    "            else:\n",
    "                suffix_feature = suffix_feature+[0]\n",
    "\n",
    "    feature_vector['prefix_feature']=prefix_feature\n",
    "    feature_vector['suffix_feature']=suffix_feature\n",
    "\n",
    "    # Feature 6: Check if the token is already in the DrugBank database\n",
    "    \n",
    "    \n",
    "    # Feature \n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "# feature vector\n",
    "features = feature_vector(train_set['token'])\n",
    "\n",
    "# joining two dictionaries\n",
    "train_set = {**train_set,**features}\n",
    "# creating the data frame\n",
    "train_df = pd.DataFrame(train_set)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the classifier\n",
    "## Support Vector Machines\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "- Effective in high dimensional spaces.\n",
    "- Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "- If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "- SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesc/Anaconda3/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/cesc/Anaconda3/anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/cesc/Anaconda3/anaconda/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name of the target variable\n",
    "target_name = 'output'\n",
    "token_name = 'token'\n",
    "\n",
    "# Create the appropiate data structure to pass it to the SVM.\n",
    "# X columns should be all but target_name and token_name\n",
    "X = train_df.loc[:, [all(x) for x in list(zip(train_df.columns!=target_name,train_df.columns!=token_name))]]\n",
    "# X = train_df.loc[:,train_df.columns!=target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_capitalized</th>\n",
       "      <th>is_total_capitalized</th>\n",
       "      <th>prefix_feature</th>\n",
       "      <th>suffix_feature</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_capitalized  is_total_capitalized  prefix_feature  suffix_feature  \\\n",
       "0               1                     1               0               0   \n",
       "1               1                     0               0               1   \n",
       "2               0                     0               0               0   \n",
       "3               0                     0               0               0   \n",
       "4               0                     0               0               0   \n",
       "\n",
       "   token_length  \n",
       "0             5  \n",
       "1             6  \n",
       "2             4  \n",
       "3            11  \n",
       "4             7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    O\n",
       "1    O\n",
       "2    O\n",
       "3    O\n",
       "4    O\n",
       "Name: output, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train_df[target_name]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning SVM in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a SVM object with the corresponding tunned parameters\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting with just one test text. Le'ts tokenize it, and create its feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Periodic', 'measurement', 'of', 'serum', 'PSA', 'levels', 'may', 'also', 'be', 'considered', '.']\n"
     ]
    }
   ],
   "source": [
    "token_test_text = nltk.word_tokenize(test_texts[6])\n",
    "print(token_test_text)\n",
    "\n",
    "features = pd.DataFrame(feature_vector(token_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_capitalized</th>\n",
       "      <th>is_total_capitalized</th>\n",
       "      <th>prefix_feature</th>\n",
       "      <th>suffix_feature</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_capitalized  is_total_capitalized  prefix_feature  suffix_feature  \\\n",
       "0               1                     0               0               0   \n",
       "1               0                     0               0               0   \n",
       "2               0                     0               0               0   \n",
       "3               0                     0               0               0   \n",
       "4               1                     1               0               0   \n",
       "\n",
       "   token_length  \n",
       "0             8  \n",
       "1            11  \n",
       "2             2  \n",
       "3             5  \n",
       "4             3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for text,entities in test_texts_entities:\n",
    "    # print('text: ', text)\n",
    "    # print('real entities: ',entities,'\\n')\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    predicted_tags = clf.predict(pd.DataFrame(feature_vector(tokens)))\n",
    "    predictions.append((list(predicted_tags),entities,text)) \n",
    "    # print('predicted bio tags: ',predicted_tags,'\\n')\n",
    "    \n",
    "# predictions is a list of tupples comprised of predicted tags and the true drugs we should extract from there\n",
    "# print('predictions of text 1: ',predictions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, le'ts define a function that recover's the whole drug name from BIO taggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bio_tags_to_entities(tokens,bio_tags):\n",
    "    entities = []\n",
    "    prev_tag = 'O'\n",
    "    word = ''\n",
    "    for idx in range(0,len(bio_tags)-1):\n",
    "        tag = bio_tags[idx]\n",
    "        if tag=='B':\n",
    "            if prev_tag in ['B','I']:\n",
    "                # si trobo una nova B i la previa era B o I, envio la word previa\n",
    "                entities = entities + [word]\n",
    "            word = tokens[idx]\n",
    "            prev_tag='B'\n",
    "        elif tag =='I':\n",
    "            # si trobo una I, actualitzo la word\n",
    "            word == word + tokens[idx]\n",
    "            prev_tag='I'\n",
    "        elif tag == 'O' and prev_tag in ['B','I']:\n",
    "            # si em trobo una O pero abans tenia una B o una I, envio la word previa\n",
    "            entities = entities + [word]\n",
    "            prev_tag='O'\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # print(tokens)\n",
    "    # print(bio_tags)\n",
    "    # print(entities)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "\n",
    "\n",
    "# Un exemple aprofitant l'exemple de prediccio d'abans\n",
    "bio_tags_to_entities(token_test_text,clf.predict(pd.DataFrame(feature_vector(token_test_text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation will be based on $$F1=\\frac{2*precision*recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest exemple m'ha ajudat a entendre com calcular la precision i la recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "true = ['hola','que','ca','bo']\n",
    "pred = ['hola','que','pet']\n",
    "\n",
    "print(round(len([word for word in pred if word in true])/len(pred),2))\n",
    "print(round(len([word for word in pred if word in true])/len(true),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_precision(pred_ent,true_ent):\n",
    "    if len(pred_ent) == 0 or len(true_ent) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(len([word for word in pred_ent if word in true_ent])/len(pred_ent),2)*100     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_recall(pred_ent,true_ent):\n",
    "    if len(pred_ent) == 0 or len(true_ent) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(len([word for word in pred_ent if word in true_ent])/len(true_ent),2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recover all the words from the predicted bio_tags and try to compute F1 for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  25.0\n",
      "recall:  18.944444444444443\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "precision = []\n",
    "recall = []\n",
    "for tags, true_entities, text in predictions:\n",
    "    # I need the tokens for the bio_tags_to_entities function\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    predicted_entities = bio_tags_to_entities(tokens,tags)\n",
    "    precision = precision + [compute_precision(predicted_entities,true_entities)]\n",
    "    recall = recall + [compute_recall(predicted_entities,true_entities)]\n",
    "\n",
    "    \n",
    "avg_precision = statistics.mean(precision)\n",
    "avg_recall = statistics.mean(recall)\n",
    "print('precision: ',avg_precision)\n",
    "print('recall: ',avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
