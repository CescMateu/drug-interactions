{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import xml.etree.ElementTree as ET # ElementTree Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('/Users/cesc/Downloads/DrugBank_database.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "root = tree.getroot()\n",
    "for drug in root.findall('{http://www.drugbank.ca}drug'):\n",
    "    entities.append(drug.find('{http://www.drugbank.ca}name').text)\n",
    "    \n",
    "    # Look for product names with the drug\n",
    "    for drug_prod in drug.findall('{http://www.drugbank.ca}products'):\n",
    "        for drug_prod in drug_prod.iter('{http://www.drugbank.ca}product'):\n",
    "            for drug_prod_name in drug_prod.iter('{http://www.drugbank.ca}name'):\n",
    "                # Only append the product if is formed by one word\n",
    "                if len(drug_prod_name.text.split(' ')) == 1:\n",
    "                    entities.append(drug_prod_name.text)\n",
    "\n",
    "# Retain only the unique entities\n",
    "entities = set(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the 'entities' list into a file for later use\n",
    "with(open('data/drugbank_entities_not_processed.txt', 'w')) as f:\n",
    "    for i in entities:\n",
    "        f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19135"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file\n",
    "with(open('data/drugbank_entities_not_processed.txt', 'r')) as f:\n",
    "    drugbank_db = f.read().splitlines()\n",
    "\n",
    "len(drugbank_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50093"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize all the entities\n",
    "drugbank_db_mod = []\n",
    "for entity in drugbank_db:\n",
    "    tokens = nltk.word_tokenize(entity)\n",
    "    for token in tokens:\n",
    "        drugbank_db_mod.append(token)\n",
    "        \n",
    "len(drugbank_db_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81527"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate those entities with a dash\n",
    "drugbank_db_mod2 = []\n",
    "for token in drugbank_db_mod:\n",
    "    if '-' in token:\n",
    "        split_tokens = token.split('-')\n",
    "        for token in split_tokens:\n",
    "            drugbank_db_mod2.append(token)\n",
    "    else:\n",
    "        drugbank_db_mod2.append(token)\n",
    "\n",
    "len(drugbank_db_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36553"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of common words that we don't want to include\n",
    "common_words = set(stopwords.words('english'))\n",
    "\n",
    "# Eliminate those entities that don't fullfill certain conditions\n",
    "# Length > 3, is not completely numeric, no duplicates and is not a 'stopword'\n",
    "drugbank_db_mod3 = []\n",
    "for token in drugbank_db_mod2:\n",
    "    if len(token) > 3 and not token.isnumeric() and token.lower() not in common_words:\n",
    "        drugbank_db_mod3.append(token)\n",
    "        \n",
    "len(drugbank_db_mod3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drugbank_db_mod4 = []\n",
    "for token in drugbank_db_mod3:\n",
    "    for ch in token:\n",
    "        if ch.isalpha():\n",
    "            drugbank_db_mod4.append(token)\n",
    "            break\n",
    "\n",
    "len(drugbank_db_mod4)\n",
    "\n",
    "drugbank_db_mod4 = set(drugbank_db_mod4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drugbank_db_final = [x.lower() for x in drugbank_db_mod4]\n",
    "drugbank_db_final = set(drugbank_db_final)\n",
    "\n",
    "\n",
    "with(open('data/DrugBank_names_DB.txt', 'w')) as f:\n",
    "    for entity in drugbank_db_final:\n",
    "        f.write(entity + '\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello hello\n",
      "Ibuprofeno ibuprofen\n",
      "Ibuprofeno feno\n",
      "Ibuprofeno profen\n",
      "Ibuprofeno profeno\n",
      "like like\n",
      "Aspirins aspirin\n",
      "Aspirins aspi\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Hello my name is Ibuprofeno and I like to take Aspirins from now and then Fluimucil and almax'\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "for token in tokenized_sentence:\n",
    "    for drug in drugbank_db_final:\n",
    "        if drug in token.lower():\n",
    "            print(token, drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "like\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_sentence:\n",
    "    if token.lower() in drugbank_db_final:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
